#goalï¼šå»ºç«‹æ™‚é€Ÿçš„ç›´æ–¹åœ–èˆ‡truncated normal
#æœªåšï¼šæ··åˆå¸¸æ…‹

import pandas as pd
from combined_traffic_simulator import CombinedTrafficSimulator, build_weekday_average_df
from holidays import holiday_dates
from flow_limit_generator import generate_flow_limit_table
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib
from scipy.stats import norm
import numpy as np
from scipy.stats import truncnorm
from scipy.signal import find_peaks
from sklearn.mixture import GaussianMixture

matplotlib.rcParams['font.family'] = 'Microsoft JhengHei'  # å¾®è»Ÿæ­£é»‘é«”
matplotlib.rcParams['axes.unicode_minus'] = False  # è² è™Ÿæ­£å¸¸é¡¯ç¤º

# 1ï¸âƒ£ å››æ®µè³‡æ–™è·¯å¾‘
excel_files = {
    "0021": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\å“code\traffic_pipeline\output\0021_åœ“å±±äº¤æµé“_åˆ°_å°åŒ—äº¤æµé“_final.xlsx",
    "0022": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\å“code\traffic_pipeline\output\0022_å°åŒ—äº¤æµé“_åˆ°_åœ“å±±äº¤æµé“_final.xlsx",
    "0023": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\å“code\traffic_pipeline\output\0023_å°åŒ—äº¤æµé“_åˆ°_ä¸‰é‡äº¤æµé“_final.xlsx",
    "0024": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\å“code\traffic_pipeline\output\0024_ä¸‰é‡äº¤æµé“_åˆ°_å°åŒ—äº¤æµé“_final.xlsx"
}

# 2ï¸âƒ£ å„æ®µæ¨¡å‹è·¯å¾‘
reg_model_paths = {
    "0021": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\traffic\å“\saved_models_2\0021_reg.pkl",
    "0022": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\traffic\å“\saved_models_2\0022_reg.pkl",
    "0023": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\traffic\å“\saved_models_2\0023_reg.pkl",
    "0024": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\traffic\å“\saved_models_2\0024_reg.pkl"
}
vol_model_paths = {
    "0021": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\traffic\å“\saved_models_2\0021_vol.pkl",
    "0022": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\traffic\å“\saved_models_2\0022_vol.pkl",
    "0023": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\traffic\å“\saved_models_2\0023_vol.pkl",
    "0024": r"C:\Users\User\Desktop\çˆ¶å­é—œä¿‚\çˆ¶å­é—œä¿‚\traffic\å“\saved_models_2\0024_vol.pkl"
}

# 3ï¸âƒ£ è·¯æ®µé•·åº¦ï¼ˆå–®ä½ï¼šå…¬é‡Œï¼‰
highway_lengths_km = {
    "0021": 1.9,
    "0022": 1.9,
    "0023": 2.0,
    "0024": 2.0
}

# 4ï¸âƒ£ ç”¢ç”Ÿæ¯æ®µè·¯çš„ flow limit è¡¨ï¼ˆå¦‚å·²å­˜åœ¨å¯ç•¥éï¼‰
for key in excel_files:
    generate_flow_limit_table(
        excel_file=excel_files[key],
        output_csv=f"flow_limit_{key}.csv"
    )

# 5ï¸âƒ£ flow limit å°æ‡‰è¡¨
flow_limit_csvs = {
    "0021": "flow_limit_0021.csv",
    "0022": "flow_limit_0022.csv",
    "0023": "flow_limit_0023.csv",
    "0024": "flow_limit_0024.csv"
}

# 2ï¸âƒ£ åˆä½µæ‰€æœ‰è³‡æ–™
df_all = []
for key in excel_files:
    df = pd.read_excel(excel_files[key])
    df["è·¯æ®µ"] = key
    df["æ–¹å‘"] = "å—ä¸‹" if key in ["0021", "0023"] else "åŒ—ä¸Š"
    df_all.append(df)
df_all = pd.concat(df_all, ignore_index=True)

# 3ï¸âƒ£ å»ºç«‹å¹³æ—¥å¹³å‡æ¨¡æ“¬è³‡æ–™
df_avg = build_weekday_average_df(df_all, holiday_dates)

# 4ï¸âƒ£ åˆå§‹åŒ–æ¨¡æ“¬å™¨ä¸¦é¤µå…¥å¹³å‡è³‡æ–™
simulator = CombinedTrafficSimulator(
    excel_files=excel_files,
    reg_model_paths=reg_model_paths,
    vol_model_paths=vol_model_paths,
    direction="all",
    flow_limit_csvs=flow_limit_csvs,
    highway_lengths_km=highway_lengths_km
)
simulator.df = df_avg.copy()

# 5ï¸âƒ£ åŸ·è¡Œæ¨¡æ“¬
simulator.predict_and_simulate(probabilistic=True)
df_sim = simulator.get_result_df()


def plot_hourly_speed_count_distribution(df_sim, direction="å—ä¸‹"):
    df = df_sim[df_sim["æ–¹å‘"] == direction].copy()
    df["é€²å…¥æ™‚é–“"] = pd.to_datetime(df["é€²å…¥æ™‚é–“"])
    df["hour"] = df["é€²å…¥æ™‚é–“"].dt.hour

    fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(22, 12))
    axes = axes.flatten()

    hourly_avg = df.groupby("hour")["é æ¸¬è»Šé€Ÿ"].mean()

    print(f"ğŸ“Š ç¹ªè£½ {direction} æ–¹å‘è»Šé€Ÿç›´æ–¹åœ–ï¼ˆå«çµ±è¨ˆå€¼èˆ‡å¸¸æ…‹æ“¬åˆï¼‰")
    for hour in tqdm(range(24), desc=f"{direction} ç¹ªåœ–ä¸­"):
        ax = axes[hour]
        hour_data = df[df["hour"] == hour]["é æ¸¬è»Šé€Ÿ"]

        if hour_data.empty:
            ax.set_visible(False)
            continue

        # ç•«ç›´æ–¹åœ–ï¼ˆY è»¸ç‚ºè»Šè¼›æ•¸ï¼‰
        sns.histplot(hour_data, kde=False, bins=30, stat="count",
                     ax=ax, color='orange' if direction == "å—ä¸‹" else 'blue',
                     edgecolor='black', alpha=0.85)

        ax.set_xlim(0, 120)
        ax.set_ylim(0, None)
        ax.set_title(f"{hour:02d}:00 - {hour+1:02d}:00", fontsize=10)
        ax.set_xlabel("è»Šé€Ÿ (km/h)", fontsize=8)
        ax.set_ylabel("è»Šè¼›æ•¸", fontsize=8)
        ax.tick_params(axis='both', labelsize=8)

        # çµ±è¨ˆå€¼ï¼ˆÎ¼, Ïƒ, Nï¼‰
        mu = hour_data.mean()
        std = hour_data.std()
        count = len(hour_data)
        ax.text(0.02, 0.90,
                f"Î¼={mu:.1f}, Ïƒ={std:.1f}, N={count}",
                transform=ax.transAxes,
                fontsize=8, color='black',
                verticalalignment='top', horizontalalignment='left')

        # å¹³å‡è»Šé€Ÿç´…ç·š
        if hour in hourly_avg:
            ax.axvline(hourly_avg.loc[hour], color='red', linestyle='--', linewidth=1)

        # å¸¸æ…‹åˆ†å¸ƒæ“¬åˆç·š
        try:
            fit_mu, fit_std = norm.fit(hour_data)
            x = np.linspace(0, 120, 200)
            bin_width = (hour_data.max() - hour_data.min()) / 30
            y = norm.pdf(x, fit_mu, fit_std) * count * bin_width
            ax.plot(x, y, 'black', linestyle='-', linewidth=1.2)
        except Exception as e:
            print(f"âš ï¸ æ“¬åˆå¤±æ•—ï¼ˆhour={hour}ï¼‰: {e}")

    fig.suptitle(f"{direction}æ–¹å‘ æ¯å°æ™‚è»Šé€Ÿåˆ†å¸ƒåœ–ï¼ˆå«çµ±è¨ˆ + å¸¸æ…‹æ“¬åˆï¼‰", fontsize=18)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig(f"speed_count_distribution_{direction}.png", dpi=300)
    plt.show()


print("ç•«åœ–ä¸­")
#plot_hourly_speed_count_distribution(df_sim, direction="å—ä¸‹")
#plot_hourly_speed_count_distribution(df_sim, direction="åŒ—ä¸Š")

# ç¹ªè£½çœŸå¯¦è³‡æ–™ç›´æ–¹åœ–
def plot_combined_real_and_simulated_distribution(df_real, df_sim, sigma_by_time, direction="å—ä¸‹"):
    color = '#FFA500' if direction == "å—ä¸‹" else '#1E90FF'
    df_real = df_real[df_real["æ–¹å‘"] == direction].copy()
    df_sim = df_sim[df_sim["æ–¹å‘"] == direction].copy()

    df_real["æ™‚é–“é»"] = pd.to_datetime(df_real["æ™‚é–“é»"])
    df_sim["é€²å…¥æ™‚é–“"] = pd.to_datetime(df_sim["é€²å…¥æ™‚é–“"])
    df_real["hour"] = df_real["æ™‚é–“é»"].dt.hour
    df_sim["hour"] = df_sim["é€²å…¥æ™‚é–“"].dt.hour

    fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(22, 12))
    axes = axes.flatten()

    for hour in range(24):
        ax = axes[hour]

        real_data = df_real[df_real["hour"] == hour]["TravelSpeed"]
        sim_data = df_sim[df_sim["hour"] == hour]["é æ¸¬è»Šé€Ÿ"]

        if real_data.empty or sim_data.empty:
            ax.set_visible(False)
            continue

        # ğŸš¨ å¤šå³°åµæ¸¬ï¼ˆå‹•æ…‹é–€æª»ï¼‰
        counts, bins = np.histogram(real_data, bins=30)
        bin_centers = (bins[:-1] + bins[1:]) / 2
        count_max = np.max(counts)
        prominence_thresh = max(count_max * 0.1, 100)
        height_thresh = max(count_max * 0.15, 80)

        from scipy.signal import find_peaks
        peaks, properties = find_peaks(
            counts,
            prominence=prominence_thresh,
            height=height_thresh,
            distance=2
        )
        peak_positions = bin_centers[peaks]
        num_peaks = len(peaks)
        is_multi_peak = num_peaks >= 2 and (peak_positions[-1] - peak_positions[0]) > 10

        # ğŸ”¶ çœŸå¯¦è³‡æ–™ç›´æ–¹åœ–
        sns.histplot(real_data, kde=False, bins=8, stat="count",
                     ax=ax, color=color, edgecolor='black', alpha=0.7, label="çœŸå¯¦")

        # ğŸ”· æ¨¡æ“¬åˆ†å¸ƒç·šï¼šæ ¹æ“šå¤šå³°è‡ªå‹•èª¿æ•´ GMM æˆåˆ†æ•¸
        sim_data_nonan = sim_data.dropna().values.reshape(-1, 1)
        if len(sim_data_nonan) >= 50:
            n_components = min(max(num_peaks, 1), 4)  # è‡³å°‘ 1 ç¾¤ï¼Œæœ€å¤š 4 ç¾¤
            gmm = GaussianMixture(n_components=n_components, random_state=42)
            gmm.fit(sim_data_nonan)
            weights = gmm.weights_
            mus = gmm.means_.flatten()
            sigmas = np.sqrt(gmm.covariances_).flatten()

            x = np.linspace(0, 120, 300)
            bin_width = (real_data.max() - real_data.min()) / 30
            total_pdf = np.zeros_like(x)

            for w, mu, sigma in zip(weights, mus, sigmas):
                a, b = (mu - 4 * sigma - mu) / sigma, (mu + 4 * sigma - mu) / sigma
                pdf = truncnorm.pdf(x, a, b, loc=mu, scale=sigma)
                total_pdf += w * pdf

            scaled_pdf = total_pdf * len(real_data) * bin_width
            ax.plot(x, scaled_pdf, color='darkgreen', linewidth=1.5,
                    label=f"æ¨¡æ“¬æ··åˆæˆªå°¾åˆ†å¸ƒï¼ˆ{n_components} ç¾¤ï¼‰")

            mu = np.sum(weights * mus)  # æ··åˆå¹³å‡ Î¼
            sigma = np.sqrt(np.sum(weights * (sigmas ** 2 + (mus - mu) ** 2)))  # æ··åˆç¸½é«” Ïƒ
        else:
            # fallback å–®ä¸€æˆªå°¾å¸¸æ…‹
            mu = sim_data.mean()
            sigma = sigma_by_time.get(f"{hour:02d}:00", 3)
            a, b = (mu - 4 * sigma - mu) / sigma, (mu + 4 * sigma - mu) / sigma
            x = np.linspace(mu - 4 * sigma, mu + 4 * sigma, 300)
            x = np.clip(x, 0, 120)
            pdf = truncnorm.pdf(x, a, b, loc=mu, scale=sigma)
            bin_width = (real_data.max() - real_data.min()) / 30
            scaled_pdf = pdf * len(real_data) * bin_width
            ax.plot(x, scaled_pdf, color='darkgreen', linewidth=1.5, label="æ¨¡æ“¬æˆªå°¾åˆ†å¸ƒ")

        # åœ–è¡¨æ¨™é¡Œèˆ‡æ ¼å¼
        ax.set_xlim(0, 120)
        title = f"{hour:02d}:00 - {hour + 1:02d}:00"
        if is_multi_peak:
            title += f"{num_peaks} å³°"
        ax.set_title(title, fontsize=10)

        ax.set_xlabel("è»Šé€Ÿ (km/h)", fontsize=8)
        ax.set_ylabel("è»Šè¼›æ•¸", fontsize=8)
        ax.tick_params(axis='both', labelsize=8)
        ax.legend(fontsize=7, loc="upper right")
        ax.text(0.02, 0.95, f"Î¼={mu:.1f}, Ïƒ={sigma:.1f}", transform=ax.transAxes, fontsize=8)

    fig.suptitle(f"{direction}æ–¹å‘ æ¯å°æ™‚è»Šé€Ÿåˆ†å¸ƒï¼ˆçœŸå¯¦ç›´æ–¹åœ– + æˆªå°¾å¸¸æ…‹ PDFï¼‰", fontsize=18)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()



plot_combined_real_and_simulated_distribution(df_all, df_sim, simulator.sigma_by_time, direction="å—ä¸‹")
plot_combined_real_and_simulated_distribution(df_all, df_sim, simulator.sigma_by_time, direction="åŒ—ä¸Š")

def plot_multi_peak_hours(df_real, df_sim, sigma_by_time, direction="å—ä¸‹"):
    color = '#FFA500' if direction == "å—ä¸‹" else '#1E90FF'
    df_real = df_real[df_real["æ–¹å‘"] == direction].copy()
    df_sim = df_sim[df_sim["æ–¹å‘"] == direction].copy()

    df_real["æ™‚é–“é»"] = pd.to_datetime(df_real["æ™‚é–“é»"])
    df_sim["é€²å…¥æ™‚é–“"] = pd.to_datetime(df_sim["é€²å…¥æ™‚é–“"])
    df_real["hour"] = df_real["æ™‚é–“é»"].dt.hour
    df_sim["hour"] = df_sim["é€²å…¥æ™‚é–“"].dt.hour

    multi_peak_hours = []

    for hour in range(24):
        real_data = df_real[df_real["hour"] == hour]["TravelSpeed"]
        if len(real_data) < 50:
            continue

        counts, bins = np.histogram(real_data, bins=30)
        peaks, _ = find_peaks(counts, prominence=200)  # å¯èª¿åƒæ•¸
        if len(peaks) >= 2:
            multi_peak_hours.append(hour)

    print(f"ğŸ“Œ åµæ¸¬åˆ°å¤šå³°æ™‚æ®µï¼š{multi_peak_hours}")

    n = len(multi_peak_hours)
    cols = min(6, n)
    rows = (n + cols - 1) // cols

    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols * 5, rows * 5))
    axes = np.array(axes).reshape(-1)  # å±•å¹³ä»¥æ”¯æ´å–®è¡Œä¹Ÿèƒ½ index
    for i in range(n, len(axes)):
        axes[i].axis("off")

    if len(multi_peak_hours) == 1:
        axes = [axes]

    for i, hour in enumerate(multi_peak_hours):
        ax = axes[i]

        real_data = df_real[df_real["hour"] == hour]["TravelSpeed"]
        sim_data = df_sim[df_sim["hour"] == hour]["é æ¸¬è»Šé€Ÿ"]

        sns.histplot(real_data, kde=False, bins=30, stat="count",
                     ax=ax, color=color, edgecolor='black', alpha=0.7, label="çœŸå¯¦")

        mu = sim_data.mean()
        sigma = sigma_by_time.get(f"{hour:02d}:00", 3)
        lower, upper = (mu - 4 * sigma - mu) / sigma, (mu + 4 * sigma - mu) / sigma

        x = np.linspace(mu - 4 * sigma, mu + 4 * sigma, 300)
        x = np.clip(x, 0, 120)
        trunc_pdf = truncnorm.pdf(x, lower, upper, loc=mu, scale=sigma)
        bin_width = (real_data.max() - real_data.min()) / 30
        scaled_pdf = trunc_pdf * len(real_data) * bin_width

        ax.plot(x, scaled_pdf, color='darkgreen', linewidth=1.5, label="æ¨¡æ“¬æˆªå°¾åˆ†å¸ƒ")
        ax.set_xlim(0, 120)
        ax.set_title(f"{hour:02d}:00 - {hour+1:02d}:00\nâš ï¸ å¤šå³°", fontsize=12)
        ax.set_xlabel("è»Šé€Ÿ (km/h)")
        ax.set_ylabel("è»Šè¼›æ•¸")
        ax.legend()

        ax.text(0.02, 0.95, f"Î¼={mu:.1f}, Ïƒ={sigma:.1f}", transform=ax.transAxes, fontsize=9)

    fig.suptitle(f"âš ï¸ {direction}æ–¹å‘ å¤šå³°è»Šé€Ÿåˆ†å¸ƒæ™‚æ®µï¼ˆçœŸå¯¦ç›´æ–¹åœ– + æ¨¡æ“¬æˆªå°¾ PDFï¼‰", fontsize=18)
    plt.tight_layout(rect=[0, 0.05, 1, 0.95])
    plt.savefig(f"multi_peak_hours_{direction}.png", dpi=300)
    plt.show()
print("ç•«ç¬¬äºŒç¨®åœ–...")
#plot_multi_peak_hours(df_all, df_sim, simulator.sigma_by_time, direction="å—ä¸‹")
#plot_multi_peak_hours(df_all, df_sim, simulator.sigma_by_time, direction="åŒ—ä¸Š")

# 6ï¸âƒ£ åŒ¯å‡ºçµæœ
print("è¼¸å‡ºçµæœä¸­...")
#simulator.export_vehicle_time_info("vehicle_passage_time.csv")
