import pandas as pd
import numpy as np
from sklearn.mixture import GaussianMixture
from scipy.stats import truncnorm
from scipy.signal import find_peaks
from datetime import timedelta
from holidays import holiday_dates
from tqdm import tqdm

# ====== åƒæ•¸ ======
np.random.seed(42)
MIN_SPEED, MAX_SPEED = 20, 120
ROAD_LENGTH = 2000            # 0024 å–®ä¸€è·¯æ®µé•·åº¦ (m)ï¼›å¯ä¾å¯¦éš›èª¿æ•´
MAX_COMPONENTS = 6
AUTO_COMPONENTS = True
FIXED_COMPONENTS = 2
GMM_MIN_SAMPLES = 40          # åŒä¸€æ™‚æ®µ(HH:MM)æ¨£æœ¬æ•¸è‡³å°‘è¦é€™éº¼å¤šæ‰æ“¬åˆ GMM
BIN_SECONDS = 300             # æ¯ 5 åˆ†é˜çª—é•·åº¦
BASE_DATE = "2025-01-01"      # 24h è¼¸å‡ºä½¿ç”¨çš„åŸºæº–æ—¥æœŸï¼ˆåƒ…ä½œæ¨™ç±¤ï¼‰
P_RAMP = 0.25                  # åŒé“æ¯”ä¾‹

FILE_0024 = r"C:\Users\User\Desktop\äº¤é€šéƒ¨\äº¤é€šéƒ¨ç«¶è³½\data_2025\0024_ä¸‰é‡äº¤æµé“_åˆ°_å°åŒ—äº¤æµé“_final.xlsx"

# ====== éæ¿¾ï¼šå‰”é™¤ç¯€æ—¥èˆ‡é€±æœ« ======
def filter_weekdays(df):
    df = df.copy()
    df_days = df["æ™‚é–“é»"].dt.floor("D")
    df = df[~df_days.isin(pd.to_datetime(holiday_dates))]
    df = df[df["æ™‚é–“é»"].dt.weekday < 5]
    df["æ™‚é–“æ®µ"] = df["æ™‚é–“é»"].dt.floor("5min")
    df["æ™‚é–“_hm"] = df["æ™‚é–“æ®µ"].dt.strftime("%H:%M")
    return df

# ====== ç”Ÿæˆ 24h Ã— 5min å¹³å‡è¼ªå»“ ======
def build_24h_profile(df):
    # å°æ‰€æœ‰å¹³æ—¥è³‡æ–™ï¼ŒæŒ‰ HH:MM èšåˆ
    prof = df.groupby("æ™‚é–“_hm").agg(
        avg_speed=("TravelSpeed", "mean"),
        avg_flow=("ç¸½è»Šè¼›æ•¸", "mean"),
        cnt=("TravelSpeed", "count")
    ).reset_index()

    # ç¢ºä¿ 00:00ï½23:55 çš„ 288 æ ¼éƒ½é½Šå…¨ï¼ˆç¼ºçš„è£œ 0/NaN å†è™•ç†ï¼‰
    full_hm = pd.date_range(BASE_DATE, periods=288, freq="5min").strftime("%H:%M")
    prof = prof.set_index("æ™‚é–“_hm").reindex(full_hm).reset_index().rename(columns={"index": "æ™‚é–“_hm"})

    # ç¼ºå€¼è™•ç†
    med_v = prof["avg_speed"].median() if prof["avg_speed"].notna().sum() > 0 else 80.0
    prof["avg_speed"] = prof["avg_speed"].fillna(med_v)
    prof["avg_flow"] = prof["avg_flow"].fillna(0.0).clip(lower=0.0)

    # åŠ ä¸ŠåŸºæº–æ—¥æœŸçš„å¯¦éš›æ™‚é–“è»¸
    prof["æ™‚é–“æ®µ"] = pd.to_datetime(BASE_DATE + " " + prof["æ™‚é–“_hm"])
    return prof[["æ™‚é–“æ®µ", "æ™‚é–“_hm", "avg_speed", "avg_flow"]]

# ====== æŒ‡æ•¸åˆ†å¸ƒåˆ°é”æ™‚åˆ»ï¼ˆå·²çŸ¥ç›®æ¨™åˆ°é”æ•¸ï¼‰======
def exponential_offsets(count, T=BIN_SECONDS):
    if count <= 0:
        return np.array([])
    lam = count / T
    if lam <= 0:
        return np.array([])
    intervals = np.random.exponential(scale=1.0/lam, size=count)
    offsets = np.cumsum(intervals)
    offsets[offsets > T] = T
    return np.sort(offsets)

# ====== GMM æ“¬åˆï¼ˆä»¥å…¨å¹´å¹³æ—¥ã€åŒä¸€ HH:MM æ ·æœ¬ï¼‰======
gmm_cache = {}

def fit_gmm_for_hm(hm, samples_1d):
    if hm in gmm_cache:
        return gmm_cache[hm]
    x = samples_1d.reshape(-1, 1)
    if AUTO_COMPONENTS:
        counts, _ = np.histogram(samples_1d, bins=30)
        prom = max(np.max(counts) * 0.08, 20)
        peaks, _ = find_peaks(counts, prominence=prom, distance=2)
        n_components = int(np.clip(len(peaks), 1, MAX_COMPONENTS))
    else:
        n_components = FIXED_COMPONENTS
    init_means = np.linspace(samples_1d.min(), samples_1d.max(), n_components).reshape(-1, 1)
    gmm = GaussianMixture(
        n_components=n_components,
        means_init=init_means,
        covariance_type='full',
        reg_covar=1e-3,
        random_state=42
    ).fit(x)
    gmm_cache[hm] = gmm
    return gmm

def sample_gmm_trunc(gmm, n, vmin=MIN_SPEED, vmax=MAX_SPEED):
    samples = []
    stds = np.sqrt(gmm.covariances_.reshape(-1))
    stds = np.clip(stds, 1.0, None)
    counts = np.random.multinomial(n, gmm.weights_)
    for cnt, mu, sigma in zip(counts, gmm.means_.flatten(), stds):
        if cnt > 0:
            a, b = (vmin - mu) / sigma, (vmax - mu) / sigma
            samples.extend(truncnorm.rvs(a, b, loc=mu, scale=sigma, size=cnt))
    return np.array(samples)

def sample_speeds(hm, count, hm_pool, fallback_mean):
    if count <= 0:
        return np.array([])
    arr = hm_pool.get(hm, np.array([]))
    if arr.size >= GMM_MIN_SAMPLES:
        gmm = fit_gmm_for_hm(hm, arr)
        vals = sample_gmm_trunc(gmm, count)
    else:
        sigma = 6.0
        a, b = (MIN_SPEED - fallback_mean) / sigma, (MAX_SPEED - fallback_mean) / sigma
        vals = truncnorm.rvs(a, b, loc=fallback_mean, scale=sigma, size=count)
    return np.clip(vals, MIN_SPEED, MAX_SPEED)

# ====== ä¸»ç¨‹å¼ ======
if __name__ == "__main__":
    # 1) è®€æª” + éæ¿¾
    df = pd.read_excel(FILE_0024, parse_dates=["æ™‚é–“é»"])
    df = filter_weekdays(df)

    # 2) å»º 24h å¹³å‡è¼ªå»“
    profile = build_24h_profile(df)

    # 3) æ§‹å»ºå…¨å¹´å¹³æ—¥åŒä¸€ HH:MM è»Šé€Ÿæ¨£æœ¬æ± 
    hm_pool = (
        df.groupby("æ™‚é–“_hm")["TravelSpeed"]
          .apply(lambda s: s.dropna().astype(float).values)
          .to_dict()
    )

    # 4) ä¾è¼ªå»“ç”Ÿæˆå–®æ—¥ 24h è»Šè¼›è³‡æ–™ï¼ˆåŠ å…¥ä¾†æºï¼‰
    records = []
    vehicle_id = 1
    for _, row in tqdm(profile.iterrows(), total=len(profile), desc="ğŸš— ç”Ÿæˆ 24h (0024)"):
        hm = row["æ™‚é–“_hm"]
        t_start = row["æ™‚é–“æ®µ"]
        mean_speed = float(row["avg_speed"])
        count = int(round(row["avg_flow"]))
        if count <= 0:
            continue
        speeds = sample_speeds(hm, count, hm_pool, mean_speed)
        offsets = exponential_offsets(count, BIN_SECONDS)
        enter_times = [t_start + timedelta(seconds=float(o)) for o in offsets]
        for v in range(count):
            v_kmh = float(speeds[v])
            travel_time = ROAD_LENGTH / (v_kmh / 3.6)
            exit_time = enter_times[v] + timedelta(seconds=travel_time)
            # åŒé“æˆ–ä¸»ç·šæ¨™è¨˜
            src = "åŒé“" if np.random.rand() < P_RAMP else "ä¸»ç·š"
            records.append([
                vehicle_id, t_start, enter_times[v], v_kmh, travel_time, exit_time, src
            ])
            vehicle_id += 1

    # 5) è¼¸å‡º
    cols = ["è»Šè¼›ID", "æ™‚æ®µ", "é€²å…¥æ™‚é–“", "æœŸæœ›é€Ÿåº¦(km/h)", "è¡Œé§›æ™‚é–“(s)", "é€€å‡ºæ™‚é–“", "ä¾†æº"]
    df_out = pd.DataFrame(records, columns=cols)
    out_path = r"C:\Users\User\Desktop\äº¤é€šéƒ¨\äº¤é€šéƒ¨ç«¶è³½\new_train\xgboost\v5æ¨¡æ“¬\sim_0024_outputs\figs\vehicles_0024_24h_profile.csv"
    df_out.to_csv(out_path, index=False, encoding="utf-8-sig")

    # 6) æ‘˜è¦
    print("====== ç”Ÿæˆå®Œæˆï¼ˆåƒ… 24 å°æ™‚ï¼‰======")
    print("ç¸½ 5 åˆ†é˜å€é–“æ•¸ï¼š", profile.shape[0])
    print("ç¸½è»Šè¼›æ•¸ï¼š", df_out.shape[0])
    print("è¼¸å‡ºæª”æ¡ˆï¼š", out_path)
