import pandas as pd
import joblib
import numpy as np
from tqdm import tqdm
from holidays import holiday_dates
from scipy.stats import truncnorm
from sklearn.mixture import GaussianMixture

class CombinedTrafficSimulator:
    def __init__(self, excel_files, reg_model_paths, vol_model_paths,
                 direction="all", flow_limit_csvs=None, highway_lengths_km=None):
        self.directions = {
            "å—ä¸‹": ["0021", "0023"],
            "åŒ—ä¸Š": ["0022", "0024"]
        }

        if direction == "all":
            self.selected_keys = self.directions["å—ä¸‹"] + self.directions["åŒ—ä¸Š"]
        elif direction in self.directions:
            self.selected_keys = self.directions[direction]
        else:
            raise ValueError("direction å¿…é ˆç‚º 'å—ä¸‹'ã€'åŒ—ä¸Š' æˆ– 'all'")

        self.reg_models = {}
        self.vol_models = {}
        self.flow_limit = {}
        self.vehicles = []

        self.highway_lengths = {k: int(highway_lengths_km.get(k, 1.9) * 1000)
                                for k in self.selected_keys}

        if flow_limit_csvs:
            for key in self.selected_keys:
                if key in flow_limit_csvs:
                    limit_df = pd.read_csv(flow_limit_csvs[key])
                    self.flow_limit[key] = dict(zip(limit_df["æ™‚é–“å­—ä¸²"], limit_df["æµé‡ä¸Šé™"]))
            print(f"âœ… å·²è¼‰å…¥ flow limitï¼ˆå…± {len(self.flow_limit)} è·¯æ®µï¼‰")

        df_list = []
        for key in self.selected_keys:
            df = pd.read_excel(excel_files[key])
            df["è·¯æ®µ"] = key
            df["æ–¹å‘"] = "å—ä¸‹" if key in self.directions["å—ä¸‹"] else "åŒ—ä¸Š"
            df["æ—¥æœŸ"] = pd.to_datetime(df["æ™‚é–“é»"]).dt.strftime("%Y-%m-%d")
            df_list.append(df)

        self.df = pd.concat(df_list, ignore_index=True)
        self.df["æ™‚é–“é»"] = pd.to_datetime(self.df["æ™‚é–“é»"])
        # âœ… æ¯å€‹æ™‚é–“å­—ä¸²ï¼ˆHH:MMï¼‰å°æ‡‰çš„æ­·å²æ¨™æº–å·®
        self.df["æ™‚é–“å­—ä¸²"] = self.df["æ™‚é–“é»"].dt.strftime("%H:%M")
        self.df_all_raw = self.df.copy()  # åŸå§‹æœ‰ TravelSpeed çš„ç‰ˆæœ¬
        self.sigma_by_time = (
            self.df.groupby("æ™‚é–“å­—ä¸²")["TravelSpeed"]
            .std()
            .fillna(3)
            .to_dict()
        )
        print(f"âœ… å…±è®€å…¥ {len(self.df)} ç­†è³‡æ–™")

    def predict_and_simulate(self, probabilistic=False):
        from scipy.stats import truncnorm
        from scipy.signal import find_peaks

        vehicle_id = 0
        records = []
        self.vehicles = []

        df_sorted = self.df.sort_values(["æ™‚é–“é»", "è·¯æ®µ"])
        entry_only_keys = [k for k in self.selected_keys if k in ["0021", "0022"]]

        for key in tqdm(entry_only_keys, desc="åƒ…å¾é€²å…¥è·¯æ®µæ¨¡æ“¬ç”¢è»Š"):
            sub_df = df_sorted[df_sorted["è·¯æ®µ"] == key].copy()
            sub_df = sub_df.rename(columns={
                "é æ¸¬è»Šé€Ÿ": "base_speed",
                "é æ¸¬è»Šæµé‡": "flow"
            })

            for _, row in tqdm(sub_df.iterrows(), total=len(sub_df), desc=f"  è™•ç†è·¯æ®µ {key}"):
                time = row["æ™‚é–“é»"]
                direction = row["æ–¹å‘"]
                time_str = time.strftime("%H:%M")
                flow = row["flow"]
                base_speed = row["base_speed"]

                if self.flow_limit.get(key) and time_str in self.flow_limit[key]:
                    flow = min(flow, self.flow_limit[key][time_str])

                if flow < 0 or np.isnan(flow):
                    continue

                num_vehicles = int(round(flow))

                if probabilistic:
                    # ğŸ” æ“¬åˆçœŸå¯¦è»Šé€Ÿåˆ†å¸ƒçš„ GMM
                    real_data = self.df_all_raw[
                        (self.df_all_raw["è·¯æ®µ"] == key) &
                        (self.df_all_raw["æ™‚é–“å­—ä¸²"] == time_str)
                        ]["TravelSpeed"].dropna()

                    if len(real_data) >= 50:
                        counts, bins = np.histogram(real_data, bins=30)
                        prominence_thresh = max(np.max(counts) * 0.1, 100)
                        height_thresh = max(np.max(counts) * 0.15, 80)
                        peaks, _ = find_peaks(
                            counts,
                            prominence=prominence_thresh,
                            height=height_thresh,
                            distance=2
                        )

                        num_components = max(1, min(len(peaks), 4))  # è‡³å°‘1ç¾¤ï¼Œæœ€å¤š4ç¾¤

                        gmm = GaussianMixture(n_components=num_components, random_state=42)
                        gmm.fit(real_data.values.reshape(-1, 1))
                        weights = gmm.weights_
                        mus = gmm.means_.flatten()
                        sigmas = np.sqrt(gmm.covariances_).flatten()

                        vehicle_speeds = []
                        for _ in range(num_vehicles):
                            comp = np.random.choice(np.arange(num_components), p=weights)
                            mu = mus[comp]
                            sigma = sigmas[comp]
                            a, b = (mu - 4 * sigma - mu) / sigma, (mu + 4 * sigma - mu) / sigma
                            speed = truncnorm.rvs(a, b, loc=mu, scale=sigma)
                            vehicle_speeds.append(speed)
                    else:
                        # fallbackï¼šå–®ä¸€æˆªå°¾å¸¸æ…‹
                        sigma = self.sigma_by_time.get(time_str, 3)
                        a, b = (base_speed - 4 * sigma - base_speed) / sigma, (
                                    base_speed + 4 * sigma - base_speed) / sigma
                        vehicle_speeds = truncnorm.rvs(a, b, loc=base_speed, scale=sigma, size=num_vehicles)

                    for i in range(num_vehicles):
                        speed = vehicle_speeds[i]
                        speed_mps = speed / 3.6
                        dist = min(speed_mps * 300, self.highway_lengths[key])
                        offset = np.random.exponential(scale=1.5)
                        enter_time = time + pd.to_timedelta(offset, unit='s')

                        records.append({
                            "è»Šè¼›ID": vehicle_id,
                            "é€²å…¥æ™‚é–“": enter_time,
                            "æ–¹å‘": direction,
                            "è·¯æ®µ": key,
                            "é æ¸¬è»Šé€Ÿ": speed,
                            "æ¨¡æ“¬è¡Œé§›è·é›¢": dist
                        })
                        vehicle_id += 1

                else:
                    # éæ©Ÿç‡æ¨¡æ“¬
                    num_vehicles = min(num_vehicles, 1000)
                    speed_mps = base_speed / 3.6
                    dist = min(speed_mps * 300, self.highway_lengths[key])

                    for _ in range(num_vehicles):
                        records.append({
                            "è»Šè¼›ID": vehicle_id,
                            "é€²å…¥æ™‚é–“": time,
                            "æ–¹å‘": direction,
                            "è·¯æ®µ": key,
                            "é æ¸¬è»Šé€Ÿ": base_speed,
                            "æ¨¡æ“¬è¡Œé§›è·é›¢": dist
                        })
                        vehicle_id += 1

        self.vehicles = pd.DataFrame(records)
        print(f"\nâœ… æ¨¡æ“¬å®Œæˆï¼Œç¸½è»Šè¼›æ•¸ï¼š{len(self.vehicles):,}")
        print("\nğŸ“Š å„è·¯æ®µæ¨¡æ“¬è»Šè¼›æ•¸ï¼š")
        print(self.vehicles["è·¯æ®µ"].value_counts())

        total_count = len(self.vehicles)
        avg_speed = self.vehicles["é æ¸¬è»Šé€Ÿ"].mean()
        min_time = self.vehicles["é€²å…¥æ™‚é–“"].min().strftime("%H:%M:%S")
        max_time = self.vehicles["é€²å…¥æ™‚é–“"].max().strftime("%H:%M:%S")
        unique_roads = sorted(self.vehicles["è·¯æ®µ"].unique())

        print("\nğŸ“‹ æ¨¡æ“¬ç¸½çµï¼š")
        print(f"ğŸ”¢ ç¸½è»Šè¼›æ•¸ï¼š{total_count:,} å°")
        print(f"ğŸš— å¹³å‡é æ¸¬è»Šé€Ÿï¼š{avg_speed:.2f} km/h")
        print(f"ğŸ•’ æ¨¡æ“¬æ™‚æ®µï¼š{min_time} ï½ {max_time}")
        print(f"ğŸ“ æ¶‰åŠè·¯æ®µï¼š{len(unique_roads)} æ®µï¼ˆ{', '.join(unique_roads)}ï¼‰")

    def get_result_df(self):
        if self.vehicles is not None:
            return self.vehicles.copy()
        else:
            print("âš ï¸ å°šæœªæ¨¡æ“¬ï¼Œè«‹å…ˆåŸ·è¡Œ predict_and_simulate()")
            return None

    def export_vehicle_time_info(self, output_csv="vehicle_passage_time.csv"):
        if self.vehicles is None or self.vehicles.empty:
            print("âš ï¸ å°šæœªæ¨¡æ“¬ï¼Œè«‹å…ˆåŸ·è¡Œ predict_and_simulate()")
            return

        df = self.vehicles.copy()
        df = df.sort_values(["è»Šè¼›ID", "é€²å…¥æ™‚é–“"])
        group_cols = ["è»Šè¼›ID", "æ–¹å‘"]

        records = []
        grouped = df.groupby(group_cols)

        for (vid, direction), group in tqdm(grouped, desc="â±ï¸ åŒ¯å‡ºé€²å‡ºèˆ‡é›¢æ®µæ™‚é–“", total=len(grouped)):
            enter_time = group["é€²å…¥æ™‚é–“"].min()
            avg_speed = group["é æ¸¬è»Šé€Ÿ"].mean()
            speed_mps = avg_speed / 3.6

            if direction == "å—ä¸‹":
                dist1 = self.highway_lengths.get("0021", 0)
                dist2 = self.highway_lengths.get("0023", 0)
            else:
                dist1 = self.highway_lengths.get("0022", 0)
                dist2 = self.highway_lengths.get("0024", 0)

            total_dist = dist1 + dist2
            duration_total = total_dist / speed_mps
            duration_1 = dist1 / speed_mps
            duration_2 = dist2 / speed_mps

            exit_time = enter_time + pd.to_timedelta(duration_total, unit="s")
            exit_road1 = enter_time + pd.to_timedelta(duration_1, unit="s")
            exit_road2 = exit_time

            records.append({
                "è»Šè¼›ID": vid,
                "æ–¹å‘": direction,
                "é€²å…¥æ™‚é–“": enter_time,
                "é›¢é–‹æ™‚é–“": exit_time,
                "é›¢é–‹æ™‚é–“_è·¯æ®µ1": exit_road1,
                "é›¢é–‹æ™‚é–“_è·¯æ®µ2": exit_road2,
                "å¹³å‡è»Šé€Ÿ(km/h)": round(avg_speed, 2),
                "ç¸½è·é›¢(m)": total_dist,
                "é€šéæ™‚é–“(sec)": round(duration_total, 1)
            })

        df_out = pd.DataFrame(records)
        df_out.to_csv(output_csv, index=False, encoding="utf-8-sig")
        print(f"âœ… å·²è¼¸å‡ºæ¯è»Šé€²å‡ºèˆ‡è·¯æ®µé›¢é–‹æ™‚é–“è³‡è¨Šåˆ°ï¼š{output_csv}")

# âœ… æ–°å¢å‡½æ•¸ï¼šå»ºç«‹å¹³æ—¥å¹³å‡è¼¸å…¥è³‡æ–™
def build_weekday_average_df(df_all, holiday_dates):
    df_all = df_all.copy()
    df_all["æ™‚é–“é»"] = pd.to_datetime(df_all["æ™‚é–“é»"])
    df_all["æ—¥æœŸ"] = df_all["æ™‚é–“é»"].dt.strftime("%Y-%m-%d")
    df_all["æ™‚é–“å­—ä¸²"] = df_all["æ™‚é–“é»"].dt.strftime("%H:%M")
    df_all["Weekday"] = df_all["æ™‚é–“é»"].dt.weekday

    df_all = df_all[
        (df_all["Weekday"] < 5) &
        (~df_all["æ—¥æœŸ"].isin(holiday_dates))
    ]

    df_avg = df_all.groupby(["è·¯æ®µ", "æ™‚é–“å­—ä¸²", "æ–¹å‘"]).agg({
        "TravelSpeed": "mean",
        "ç¸½è»Šè¼›æ•¸": "mean"
    }).reset_index()

    df_avg["æ™‚é–“é»"] = pd.to_datetime("2023-10-25 " + df_avg["æ™‚é–“å­—ä¸²"])
    df_avg = df_avg.rename(columns={"TravelSpeed": "é æ¸¬è»Šé€Ÿ", "ç¸½è»Šè¼›æ•¸": "é æ¸¬è»Šæµé‡"})

    return df_avg
